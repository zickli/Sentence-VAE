{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-13T23:26:14.570375Z",
     "start_time": "2024-06-13T23:26:11.187202Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T23:29:30.018059Z",
     "start_time": "2024-06-13T23:29:30.004449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "articles_path = './bbc-news-summary-c/News Articles'\n",
    "summaries_path = './bbc-news-summary-c/Summaries'\n",
    "categories_list = ['politics', 'sport', 'tech', 'entertainment', 'business']\n",
    "# categories_list = ['tech']"
   ],
   "id": "76c55e2a1e9d8f55",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T23:29:30.521858Z",
     "start_time": "2024-06-13T23:29:30.506222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_files_from_folders(articles_path, summaries_path, categories_list=['tech', 'sport'], encoding=\"ISO-8859-1\"):\n",
    "    articles = []\n",
    "    summaries = []\n",
    "    categories = []\n",
    "    for category in categories_list:\n",
    "        article_paths = glob.glob(os.path.join(articles_path, category, '*.txt'), recursive=True)\n",
    "        summary_paths = glob.glob(os.path.join(summaries_path, category, '*.txt'), recursive=True)\n",
    "\n",
    "        if len(article_paths) != len(summary_paths):\n",
    "            print('number of files is not equal')\n",
    "            return\n",
    "        for i in range(len(article_paths)):\n",
    "            categories.append(category)\n",
    "            with open(article_paths[i], mode='r', encoding=encoding) as file:\n",
    "                articles.append(file.read())\n",
    "\n",
    "            with open(summary_paths[i], mode='r', encoding=encoding) as file:\n",
    "                summaries.append(file.read())\n",
    "    return articles, summaries, categories"
   ],
   "id": "e3b8e13f67c50376",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T23:29:31.428884Z",
     "start_time": "2024-06-13T23:29:31.245238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "articles, summaries, categories = read_files_from_folders(articles_path, summaries_path, categories_list)\n",
    "df = pd.DataFrame({'articles': articles, 'summaries': summaries, 'categories': categories})"
   ],
   "id": "3eda6c6d17b00b4b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T23:29:32.058433Z",
     "start_time": "2024-06-13T23:29:32.042785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df[['articles', 'summaries']]\n",
    "df = df.dropna()\n",
    "train_df, test_df = train_test_split(df, test_size=0.1)"
   ],
   "id": "ffe87c34d8b5c273",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T23:29:32.574908Z",
     "start_time": "2024-06-13T23:29:32.543383Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "9f3221f33f7b7162",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               articles  \\\n",
       "0     labour plans maternity pay rise maternity pay ...   \n",
       "1     watchdog probes e mail deletions the informati...   \n",
       "2     hewitt decries career sexism plans to extend p...   \n",
       "3     labour chooses manchester the labour party wil...   \n",
       "4     brown ally rejects budget spree chancellor gor...   \n",
       "...                                                 ...   \n",
       "2220  trial begins of spain top banker the trial of ...   \n",
       "2221  uk economy ends year with spurt the uk economy...   \n",
       "2222  healthsouth ex boss goes on trial the former h...   \n",
       "2223  euro firms miss out on optimism more than N of...   \n",
       "2224  lacroix label bought by us firm luxury goods g...   \n",
       "\n",
       "                                              summaries  \n",
       "0     she said her party would boost maternity pay i...  \n",
       "1     all e mails are subject to the freedom of info...  \n",
       "2     ms hewitt also announced a new drive to help w...  \n",
       "3     the labour party will hold its N autumn confer...  \n",
       "4     but mr balls a prospective labour mp said he w...  \n",
       "...                                                 ...  \n",
       "2220  both executives helped mr botin orchestrate sp...  \n",
       "2221  simon rubinsohn chief economist at gerrard sai...  \n",
       "2222  several former healthsouth employees have alre...  \n",
       "2223  possibly as a result the worry about low cost ...  \n",
       "2224  lvmh said the french designer haute couture an...  \n",
       "\n",
       "[2225 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles</th>\n",
       "      <th>summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>labour plans maternity pay rise maternity pay ...</td>\n",
       "      <td>she said her party would boost maternity pay i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>watchdog probes e mail deletions the informati...</td>\n",
       "      <td>all e mails are subject to the freedom of info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hewitt decries career sexism plans to extend p...</td>\n",
       "      <td>ms hewitt also announced a new drive to help w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>labour chooses manchester the labour party wil...</td>\n",
       "      <td>the labour party will hold its N autumn confer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brown ally rejects budget spree chancellor gor...</td>\n",
       "      <td>but mr balls a prospective labour mp said he w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>trial begins of spain top banker the trial of ...</td>\n",
       "      <td>both executives helped mr botin orchestrate sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>uk economy ends year with spurt the uk economy...</td>\n",
       "      <td>simon rubinsohn chief economist at gerrard sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>healthsouth ex boss goes on trial the former h...</td>\n",
       "      <td>several former healthsouth employees have alre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>euro firms miss out on optimism more than N of...</td>\n",
       "      <td>possibly as a result the worry about low cost ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>lacroix label bought by us firm luxury goods g...</td>\n",
       "      <td>lvmh said the french designer haute couture an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T23:29:34.210497Z",
     "start_time": "2024-06-13T23:29:34.188333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "nltk.download('punkt')"
   ],
   "id": "7b63c84d9b8e3039",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lumin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T23:29:35.450720Z",
     "start_time": "2024-06-13T23:29:34.825143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "sentences = []\n",
    "\n",
    "for article in df['articles']:\n",
    "    sentences.extend(sent_tokenize(article))\n",
    "\n",
    "for summary in df['summaries']:\n",
    "    sentences.extend(sent_tokenize(summary))\n",
    "\n",
    "len(sentences)"
   ],
   "id": "bd44aee1e3e0460",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38834"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T23:29:35.980953Z",
     "start_time": "2024-06-13T23:29:35.949689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_sents, test_sents = train_test_split(sentences, test_size=0.05)\n",
    "print(len(train_sents), len(test_sents))"
   ],
   "id": "96a217d900f791da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36892 1942\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T23:29:42.219865Z",
     "start_time": "2024-06-13T23:29:42.203851Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_sents[0: 10])",
   "id": "cdc227bd973911b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the cellery worm does not spread via e mail like many other viruses.', 'however companies that decide to offshore their operations are driven not just by cost considerations.', 'nonetheless japanese firms have been stepping up capital investment and the survey found the pace is quickening.', 'an spokesman for ssl which makes the famous durex brand of condom would not to comment on market speculation .', 'the court is expected to reach a verdict in the case in the autumn.', 'he said intercept evidence was only a small part of the case against the men and some of it could not be used because it could put sources lives at risk.', 'where will this end.', 'last year the academy formed a committee to tighten the rules after the campaigns spilled over into personal attacks between studios.', 'the commission latest move comes just a few months after national telecoms regulators across europe launched a joint investigation which could lead to people being charged less for using their mobile phone when travelling abroad.', 'within that figure taxation would rise to N a rise of over N from what is expected from the current year.']\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T23:30:09.094334Z",
     "start_time": "2024-06-13T23:30:08.986576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"bbc.train.txt\", 'w') as file:\n",
    "    for sent in train_sents:\n",
    "        file.write(sent)\n",
    "        file.write('\\n')"
   ],
   "id": "c7c5920467fd328a",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T23:30:09.557953Z",
     "start_time": "2024-06-13T23:30:09.526179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"bbc.valid.txt\", 'w') as file:\n",
    "    for sent in test_sents:\n",
    "        file.write(sent)\n",
    "        file.write('\\n')"
   ],
   "id": "c8aa6fd187bac8ac",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T00:08:08.893830Z",
     "start_time": "2024-06-14T00:08:08.846422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "from model import SentenceVAE\n",
    "from utils import to_var, idx2word, interpolate"
   ],
   "id": "a98fb31e10734210",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T00:13:46.331678Z",
     "start_time": "2024-06-14T00:13:46.268751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('bbc_full/bbc.vocab.json', 'r') as file:\n",
    "    vocab_full = json.load(file)\n",
    "print(len(vocab_full['i2w']))\n",
    "\n",
    "with open('bbc_cleaned/bbc.vocab.json', 'r') as file:\n",
    "    vocab_cleaned = json.load(file)\n",
    "print(len(vocab_cleaned['i2w']))"
   ],
   "id": "cf37443983038250",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26946\n",
      "22376\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T03:46:56.975601Z",
     "start_time": "2024-06-14T03:46:56.753060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab = vocab_cleaned\n",
    "\n",
    "w2i, i2w = vocab['w2i'], vocab['i2w']\n",
    "\n",
    "model = SentenceVAE(\n",
    "    vocab_size=len(w2i),\n",
    "    sos_idx=w2i['<sos>'],\n",
    "    eos_idx=w2i['<eos>'],\n",
    "    pad_idx=w2i['<pad>'],\n",
    "    unk_idx=w2i['<unk>'],\n",
    "    max_sequence_length=50,\n",
    "    embedding_size=300,\n",
    "    rnn_type='gru',\n",
    "    hidden_size=256,\n",
    "    word_dropout=0,\n",
    "    embedding_dropout=0.5,\n",
    "    latent_size=32,\n",
    "    num_layers=2,\n",
    "    bidirectional=False\n",
    ")\n",
    "\n",
    "checkpoint = \"bin/2024-Jun-13-23-32-00/E9.pytorch\"\n",
    "\n",
    "if not os.path.exists(checkpoint):\n",
    "    raise FileNotFoundError(checkpoint)\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint))\n",
    "print(\"Model loaded from %s\" % checkpoint)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ],
   "id": "13023a10a612b266",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidirectional= False\n",
      "Model loaded from bin/2024-Jun-13-23-32-00/E9.pytorch\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T03:46:57.702536Z",
     "start_time": "2024-06-14T03:46:57.502802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "\n",
    "samples, z = model.inference(n=10)\n",
    "print('----------SAMPLES----------')\n",
    "print(*idx2word(samples, i2w=i2w, pad_idx=w2i['<pad>']), sep='\\n')\n",
    "\n",
    "z1 = torch.randn([16]).numpy()\n",
    "z2 = torch.randn([16]).numpy()\n",
    "z = to_var(torch.from_numpy(interpolate(start=z1, end=z2, steps=8)).float())\n",
    "samples, _ = model.inference(z=z)\n",
    "print('-------INTERPOLATION-------')\n",
    "print(*idx2word(samples, i2w=i2w, pad_idx=w2i['<pad>']), sep='\\n')"
   ],
   "id": "872857b297a33a67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXX\n",
      "----------SAMPLES----------\n",
      "the new book is not the only one of the most important game of the world but it is a great opportunity to be the first time in the us presidential election bdo said the uk was not a relatively strong step in the us . <eos>\n",
      "the n has been chosen by the withdrawals of the n n and n in the n years with the n consecutive nations in the n years the n has been chosen by the end of the season . <eos>\n",
      "the lib dems say the lib dems would be a parody of the election and the tories have been asked . <eos>\n",
      "the company said the organizational was not intended to be a huge factor in the us . <eos>\n",
      "the n is not a fan for the <unk> . <eos>\n",
      "it is not a good job . <eos>\n",
      "the company said the company had absorbed in the us and the us bankruptcy in the us and the us and the us subsidiary in the us . <eos>\n",
      "the government has been agnostic on the issue of the government and the tories who are not allowed to be completed by the law . <eos>\n",
      "the prime minister said the government was not a good issue of the leadership and the <unk> . <eos>\n",
      "the company said the organizational was not solely to the us and the us . <eos>\n",
      "XXXXX\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10x16 and 32x512)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[83], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m z2 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn([\u001B[38;5;241m16\u001B[39m])\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m      9\u001B[0m z \u001B[38;5;241m=\u001B[39m to_var(torch\u001B[38;5;241m.\u001B[39mfrom_numpy(interpolate(start\u001B[38;5;241m=\u001B[39mz1, end\u001B[38;5;241m=\u001B[39mz2, steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m))\u001B[38;5;241m.\u001B[39mfloat())\n\u001B[1;32m---> 10\u001B[0m samples, _ \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minference\u001B[49m\u001B[43m(\u001B[49m\u001B[43mz\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mz\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-------INTERPOLATION-------\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;241m*\u001B[39midx2word(samples, i2w\u001B[38;5;241m=\u001B[39mi2w, pad_idx\u001B[38;5;241m=\u001B[39mw2i[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m<pad>\u001B[39m\u001B[38;5;124m'\u001B[39m]), sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\Desktop\\github\\Sentence-VAE\\model.py:239\u001B[0m, in \u001B[0;36mSentenceVAE.inference\u001B[1;34m(self, n, z)\u001B[0m\n\u001B[0;32m    236\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    237\u001B[0m     batch_size \u001B[38;5;241m=\u001B[39m z\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m--> 239\u001B[0m hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlatent2hidden\u001B[49m\u001B[43m(\u001B[49m\u001B[43mz\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    241\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;66;03m# unflatten hidden state\u001B[39;00m\n\u001B[0;32m    243\u001B[0m     hidden \u001B[38;5;241m=\u001B[39m hidden\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_factor, batch_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (10x16 and 32x512)"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T03:48:31.771472Z",
     "start_time": "2024-06-14T03:48:31.740237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from utils import OrderedCounter\n",
    "\n",
    "\n",
    "class MyPTB(Dataset):\n",
    "\n",
    "    def __init__(self, sents, **kwargs):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = kwargs.get('max_sequence_length', 50)\n",
    "        self.min_occ = kwargs.get('min_occ', 3)\n",
    "\n",
    "        self.sents = sents\n",
    "        self.vocab_file = './bbc_cleaned/bbc.vocab.json'\n",
    "\n",
    "        self._create_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = str(idx)\n",
    "\n",
    "        return {\n",
    "            'input': torch.asarray(self.data[idx]['input']),\n",
    "            'target': torch.asarray(self.data[idx]['target']),\n",
    "            'length': self.data[idx]['length']\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.w2i)\n",
    "\n",
    "    @property\n",
    "    def pad_idx(self):\n",
    "        return self.w2i['<pad>']\n",
    "\n",
    "    @property\n",
    "    def sos_idx(self):\n",
    "        return self.w2i['<sos>']\n",
    "\n",
    "    @property\n",
    "    def eos_idx(self):\n",
    "        return self.w2i['<eos>']\n",
    "\n",
    "    @property\n",
    "    def unk_idx(self):\n",
    "        return self.w2i['<unk>']\n",
    "\n",
    "    def get_w2i(self):\n",
    "        return self.w2i\n",
    "\n",
    "    def get_i2w(self):\n",
    "        return self.i2w\n",
    "\n",
    "    def _load_vocab(self):\n",
    "        with open(self.vocab_file, 'r') as vocab_file:\n",
    "            vocab = json.load(vocab_file)\n",
    "\n",
    "        self.w2i, self.i2w = vocab['w2i'], vocab['i2w']\n",
    "\n",
    "    def _create_data(self):\n",
    "        self._load_vocab()\n",
    "\n",
    "        tokenizer = TweetTokenizer(preserve_case=False)\n",
    "\n",
    "        data = defaultdict(dict)\n",
    "\n",
    "        for i, line in enumerate(self.sents):\n",
    "            words = tokenizer.tokenize(line)\n",
    "\n",
    "            input = ['<sos>'] + words\n",
    "            input = input[:self.max_sequence_length]\n",
    "\n",
    "            target = words[:self.max_sequence_length - 1]\n",
    "            target = target + ['<eos>']\n",
    "\n",
    "            assert len(input) == len(target), \"%i, %i\" % (len(input), len(target))\n",
    "            length = len(input)\n",
    "\n",
    "            input.extend(['<pad>'] * (self.max_sequence_length - length))\n",
    "            target.extend(['<pad>'] * (self.max_sequence_length - length))\n",
    "\n",
    "            input = [self.w2i.get(w, self.w2i['<unk>']) for w in input]\n",
    "            target = [self.w2i.get(w, self.w2i['<unk>']) for w in target]\n",
    "\n",
    "            id = len(data)\n",
    "            data[id]['input'] = input\n",
    "            data[id]['target'] = target\n",
    "            data[id]['length'] = length\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "        # with io.open(os.path.join(self.data_dir, self.data_file), 'wb') as data_file:\n",
    "        #     data = json.dumps(data, ensure_ascii=False)\n",
    "        #     data_file.write(data.encode('utf8', 'replace'))\n",
    "\n",
    "        # self._load_data(vocab=False)"
   ],
   "id": "6f661c2bd7312af4",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T08:47:30.350922Z",
     "start_time": "2024-06-14T08:47:28.308428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reconstruction\n",
    "\n",
    "for article in df['articles'][:2]:\n",
    "    sents = [s for s in sent_tokenize(article)]\n",
    "    lens = [len(s) for s in sents]\n",
    "    ptb = MyPTB(sents)\n",
    "    \n",
    "    gen_sents = []\n",
    "\n",
    "    for i in range(len(ptb.data)):\n",
    "        input_seq = torch.asarray(ptb.data[i]['input'])\n",
    "        input_seq = input_seq.unsqueeze(0).cuda()\n",
    "        length = torch.asarray(ptb.data[i]['length'])\n",
    "        length = length.unsqueeze(0).cuda()\n",
    "\n",
    "        generations, z = model.generate(input_seq, length)\n",
    "\n",
    "        print(sents[i].lower())\n",
    "        print('--------------------------------------')\n",
    "        s = idx2word(generations, i2w=i2w, pad_idx=w2i['<pad>'])[0]\n",
    "        print(s[:-6])\n",
    "        print('======================================')\n",
    "        gen_sents.append(s)"
   ],
   "id": "ce612ccf6ee3b366",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labour plans maternity pay rise maternity pay for new mothers is to rise by n as part of new proposals announced by the trade and industry secretary patricia hewitt.\n",
      "--------------------------------------\n",
      "the government has been agnostic on the issue of the government and the country and the us and the country and the us and the country and the us .\n",
      "======================================\n",
      "it would mean paid leave would be increased to nine months by n ms hewitt told gmtv sunday programme.\n",
      "--------------------------------------\n",
      "the n has been chosen by the withdrawals of the n n in the n years with the n consecutive consecutive consecutive year in the last three months in the us .\n",
      "======================================\n",
      "other plans include letting maternity pay be given to fathers and extending rights to parents of older children.\n",
      "--------------------------------------\n",
      "the lib dems say they are not going to be a unifying force in the uk independence party .\n",
      "======================================\n",
      "the tories dismissed the maternity pay plan as desperate while the liberal democrats said it was misdirected.\n",
      "--------------------------------------\n",
      "the new book is not a symbol of the <unk> of the <unk> and the <unk> of the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "======================================\n",
      "ms hewitt said we have already doubled the length of maternity pay it was n weeks when we were elected we have already taken it up to n weeks.\n",
      "--------------------------------------\n",
      "the company said the new deal would be made in the n eurozone in n the company said it would be a huge amount of the dollar in the us .\n",
      "======================================\n",
      "we are going to extend the pay to nine months by n and the aim is to get it right up to the full n months by the end of the next parliament she said new mothers were already entitled to n months leave but that many women could not take it as only six of those months were paid.\n",
      "--------------------------------------\n",
      "the n has been chosen by the withdrawals of the n century in the us and the us and the us and the us and the us and the us and the us are to be the first turkish island who has been chosen by the end of th\n",
      "======================================\n",
      "we have made a firm commitment.\n",
      "--------------------------------------\n",
      "the company said the organizational industry would be a lucrative number of companies .\n",
      "======================================\n",
      "we will definitely extend the maternity pay from the six months where it now is to nine months that is the extra n she said ministers would consult on other proposals that could see fathers being allowed to take some of their partner maternity pay or leave period or extending the rights of flexible working to carers or parents of older children.\n",
      "--------------------------------------\n",
      "the new book claims that the new law was not a good game of the n and n in the n years that was not a crucial factor in the us presidential election said the economy was not expected to be a strong opportunity .\n",
      "======================================\n",
      "the shadow secretary of state for the family theresa may said these plans were announced by gordon brown in his pre budget review in december and tony blair is now recycling it in his desperate bid to win back women voters she said the conservatives would announce their proposals closer to the general election.\n",
      "--------------------------------------\n",
      "the lib dems say the lib dems are not going to be a unifying force in the country and the tories have been sidelined in the past year and the prime minister said the chancellor was not worried that the chancellor was speaking in the country .\n",
      "======================================\n",
      "liberal democrat spokeswoman for women sandra gidley said while mothers would welcome any extra maternity pay the liberal democrats feel this money is being misdirected she said her party would boost maternity pay in the first six months to allow more women to stay at home in that time.\n",
      "--------------------------------------\n",
      "the chancellor said the government was not trying to ensure that the chancellor would not be properly drafted in the next election .\n",
      "======================================\n",
      "ms hewitt also stressed the plans would be paid for by taxpayers not employers.\n",
      "--------------------------------------\n",
      "the government has been agnostic on the issue of the scandal .\n",
      "======================================\n",
      "but david frost director general of the british chambers of commerce warned that many small firms could be crippled by the move.\n",
      "--------------------------------------\n",
      "the n has been chosen by the withdrawals of the n and n in the n and n in the n minute .\n",
      "======================================\n",
      "while the majority of any salary costs may be covered by the government statutory pay recruitment costs advertising costs retraining costs and the strain on the company will not be he said.\n",
      "--------------------------------------\n",
      "the company said the organizational industry would be a gentle nudge to the company and the company said it would be a flavour .\n",
      "======================================\n",
      "further details of the government plans will be outlined on monday.\n",
      "--------------------------------------\n",
      "the company said the organizational was not solely to ensure that the company was not available .\n",
      "======================================\n",
      "new mothers are currently entitled to n of average earnings for the first six weeks after giving birth followed by n a week until the baby is six months old.\n",
      "--------------------------------------\n",
      "the n has been sidelined in the squad and the squad will be a great encounter .\n",
      "======================================\n",
      "watchdog probes e mail deletions the information commissioner says he is urgently asking for details of cabinet office orders telling staff to delete e mails more than three months old.\n",
      "--------------------------------------\n",
      "the service is not available commercially and that is the way of the net and the people that are not used to be protected and abused .\n",
      "======================================\n",
      "richard thomas totally condemned the deletion of e mails to prevent their disclosure under freedom of information laws coming into force on n january.\n",
      "--------------------------------------\n",
      "the virus is investigating the software to organise the software and the software that processes the site .\n",
      "======================================\n",
      "government guidance said e mails should only be deleted if they served no current purpose mr thomas said.\n",
      "--------------------------------------\n",
      "the service is not available commercially and that is the way of the market and it is a bit of how it is not a joke .\n",
      "======================================\n",
      "the tories and the lib dems have questioned the timing of the new rules.\n",
      "--------------------------------------\n",
      "the lib dems say the lib dems are not going to be a sensible issue .\n",
      "======================================\n",
      "tory leader michael howard has written to tony blair demanding an explanation of the new rules on e mail retention.\n",
      "--------------------------------------\n",
      "lib dem leader charles kennedy said the lib dems would be a unifying force in the next election .\n",
      "======================================\n",
      "on monday lib dem constitutional affairs committee chairman alan beith warned that the deletion of millions of government e mails could harm the ability of key probes like the hutton inquiry.\n",
      "--------------------------------------\n",
      "the lib dems say the lib dems are not going to be a unifying force in the party and the tories are not going to be the main issue of the party .\n",
      "======================================\n",
      "the timing of the new rules just before the freedom of information act comes into forces was too unlikely to have been a coincidence mr beith said.\n",
      "--------------------------------------\n",
      "the lib dems say the lib dems are not going to be a unifying force in the uk .\n",
      "======================================\n",
      "but a cabinet office spokeswoman said the move was not about the new laws or the destruction of important records .\n",
      "--------------------------------------\n",
      "the government has been agnostic on the issue of the government and the tories who are not allowed to be allowed to vote in the next election .\n",
      "======================================\n",
      "mr beith urged the information commissioner to look at how the e mail regime could support the freedom of information regime .\n",
      "--------------------------------------\n",
      "the new strains of the cabir is not available to the internet via the radio station in the uk and the us and the us and the us and the us and the us and the us .\n",
      "======================================\n",
      "mr thomas said the new act of parliament makes it very clear that to destroy records in order to prevent their disclosure becomes a criminal offence he said there was already clear guidance on the retention of e mails contained in a code of practice from the lord chancellor.\n",
      "--------------------------------------\n",
      "the new book claims that the new law was not a summary of the party and the tories that would be a safe haven for the party .\n",
      "======================================\n",
      "all e mails are subject to the freedom of information laws but the important thing was the content of the e mail said mr thomas.\n",
      "--------------------------------------\n",
      "the lib dems say the lib dems are not going to be a unifying force in the party and the lib dems are not worthless .\n",
      "======================================\n",
      "if in doubt retain that has been the long standing principle of the civil service and public authorities.\n",
      "--------------------------------------\n",
      "the company said the company had absorbed in the us and the us province of the us federal reserve and the us province of the vestey province .\n",
      "======================================\n",
      "it is only when you have got no further use for the particular record that it may be legitimate to destroy it.\n",
      "--------------------------------------\n",
      "the government has been agnostic on the issue of the government and the government has been widely expected to be .\n",
      "======================================\n",
      "but any deliberate destruction to avoid the possibility of later disclosure is to be totally condemned the freedom of information act will cover england wales and northern ireland from next year.\n",
      "--------------------------------------\n",
      "the new book is not the first time in the us and the us and the us and the us .\n",
      "======================================\n",
      "similar measures are being brought in at the same time in scotland.\n",
      "--------------------------------------\n",
      "i am not going to be a bit of the match .\n",
      "======================================\n",
      "it provides the public with a right of access to information held by about n public bodies subject to various exemptions.\n",
      "--------------------------------------\n",
      "the new book is the first time in the us and the us and the us and the us are to be the first seafarers to be the biggest gadget of the world .\n",
      "======================================\n",
      "its implementation will be monitored by the information commissioner.\n",
      "--------------------------------------\n",
      "the government has been agnostic on the issue of the lords and the government has been bypassed by the decision to introduce the government to introduce the government .\n",
      "======================================\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T04:45:30.295149Z",
     "start_time": "2024-06-14T04:09:42.573245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "results = []\n",
    "\n",
    "for article in df['articles']:\n",
    "    sents = [s for s in sent_tokenize(article)]\n",
    "    lens = [len(s) for s in sents]\n",
    "    ptb = MyPTB(sents)\n",
    "    \n",
    "    gen_sents = []\n",
    "\n",
    "    for i in range(len(ptb.data)):\n",
    "        input_seq = torch.asarray(ptb.data[i]['input'])\n",
    "        input_seq = input_seq.unsqueeze(0).cuda()\n",
    "        length = torch.asarray(ptb.data[i]['length'])\n",
    "        length = length.unsqueeze(0).cuda()\n",
    "\n",
    "        generations, z = model.generate(input_seq, length)\n",
    "\n",
    "        # print(sents[i].lower())\n",
    "        # print('--------------------------------------')\n",
    "        # print(*idx2word(generations, i2w=i2w, pad_idx=w2i['<pad>']))\n",
    "        s = idx2word(generations, i2w=i2w, pad_idx=w2i['<pad>'])[0]\n",
    "        # print(s[:-6])\n",
    "        # print('======================================')\n",
    "        gen_sents.append(s)\n",
    "        \n",
    "    gen_article = ' '.join(gen_sents)\n",
    "    rouge_scores = rouge.get_scores(gen_article, article, avg=True)\n",
    "    \n",
    "    results.append({\n",
    "        'article': article,\n",
    "        'generated_article': gen_article,\n",
    "        'rouge1_precision': rouge_scores['rouge-1']['p'],\n",
    "        'rouge1_recall': rouge_scores['rouge-1']['r'],\n",
    "        'rouge1_fmeasure': rouge_scores['rouge-1']['f'],\n",
    "        'rouge2_precision': rouge_scores['rouge-2']['p'],\n",
    "        'rouge2_recall': rouge_scores['rouge-2']['r'],\n",
    "        'rouge2_fmeasure': rouge_scores['rouge-2']['f'],\n",
    "        'rougeL_precision': rouge_scores['rouge-l']['p'],\n",
    "        'rougeL_recall': rouge_scores['rouge-l']['r'],\n",
    "        'rougeL_fmeasure': rouge_scores['rouge-l']['f']\n",
    "    })\n",
    "    \n",
    "results_df = pd.DataFrame(results)"
   ],
   "id": "1b84c67ae8a5b6f7",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T04:47:18.246049Z",
     "start_time": "2024-06-14T04:47:18.214786Z"
    }
   },
   "cell_type": "code",
   "source": "results_df.describe()",
   "id": "3e06f2d1394e41fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       rouge1_precision  rouge1_recall  rouge1_fmeasure  rouge2_precision  \\\n",
       "count       2225.000000    2225.000000      2225.000000       2225.000000   \n",
       "mean           0.318286       0.141892         0.194871          0.074304   \n",
       "std            0.058411       0.028173         0.033835          0.030320   \n",
       "min            0.145455       0.057692         0.085106          0.000000   \n",
       "25%            0.278481       0.122112         0.171429          0.053191   \n",
       "50%            0.311594       0.140351         0.193133          0.071429   \n",
       "75%            0.352941       0.159420         0.216561          0.091633   \n",
       "max            0.565217       0.263736         0.341709          0.218750   \n",
       "\n",
       "       rouge2_recall  rouge2_fmeasure  rougeL_precision  rougeL_recall  \\\n",
       "count    2225.000000      2225.000000       2225.000000    2225.000000   \n",
       "mean        0.035211         0.047368          0.292946       0.130619   \n",
       "std         0.013451         0.017872          0.055136       0.026648   \n",
       "min         0.000000         0.000000          0.137500       0.057692   \n",
       "25%         0.025974         0.035242          0.255556       0.111940   \n",
       "50%         0.034091         0.046205          0.287500       0.128492   \n",
       "75%         0.042918         0.057315          0.326923       0.147287   \n",
       "max         0.136585         0.168168          0.565217       0.241758   \n",
       "\n",
       "       rougeL_fmeasure  \n",
       "count      2225.000000  \n",
       "mean          0.179377  \n",
       "std           0.032161  \n",
       "min           0.085106  \n",
       "25%           0.156863  \n",
       "50%           0.177515  \n",
       "75%           0.199336  \n",
       "max           0.311558  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1_precision</th>\n",
       "      <th>rouge1_recall</th>\n",
       "      <th>rouge1_fmeasure</th>\n",
       "      <th>rouge2_precision</th>\n",
       "      <th>rouge2_recall</th>\n",
       "      <th>rouge2_fmeasure</th>\n",
       "      <th>rougeL_precision</th>\n",
       "      <th>rougeL_recall</th>\n",
       "      <th>rougeL_fmeasure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2225.000000</td>\n",
       "      <td>2225.000000</td>\n",
       "      <td>2225.000000</td>\n",
       "      <td>2225.000000</td>\n",
       "      <td>2225.000000</td>\n",
       "      <td>2225.000000</td>\n",
       "      <td>2225.000000</td>\n",
       "      <td>2225.000000</td>\n",
       "      <td>2225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.318286</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>0.194871</td>\n",
       "      <td>0.074304</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>0.047368</td>\n",
       "      <td>0.292946</td>\n",
       "      <td>0.130619</td>\n",
       "      <td>0.179377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.058411</td>\n",
       "      <td>0.028173</td>\n",
       "      <td>0.033835</td>\n",
       "      <td>0.030320</td>\n",
       "      <td>0.013451</td>\n",
       "      <td>0.017872</td>\n",
       "      <td>0.055136</td>\n",
       "      <td>0.026648</td>\n",
       "      <td>0.032161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.085106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.278481</td>\n",
       "      <td>0.122112</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.035242</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.111940</td>\n",
       "      <td>0.156863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.311594</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.193133</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.046205</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>0.128492</td>\n",
       "      <td>0.177515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.216561</td>\n",
       "      <td>0.091633</td>\n",
       "      <td>0.042918</td>\n",
       "      <td>0.057315</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.147287</td>\n",
       "      <td>0.199336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.263736</td>\n",
       "      <td>0.341709</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.136585</td>\n",
       "      <td>0.168168</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.241758</td>\n",
       "      <td>0.311558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d8f433705ff3f14b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5b4f88f36a3bcfde"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
